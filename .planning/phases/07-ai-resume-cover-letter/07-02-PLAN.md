---
phase: 07-ai-resume-cover-letter
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - resume_ai/tailor.py
  - resume_ai/cover_letter.py
  - resume_ai/validator.py
autonomous: true

must_haves:
  truths:
    - "Resume tailoring produces a TailoredResume with ONLY facts from the original resume"
    - "Cover letter references the specific company and role from the job description"
    - "LLM calls use temperature=0 for resume tailoring to minimize fabrication risk"
    - "Both functions are synchronous (wrapped via asyncio.to_thread at call site)"
    - "Post-generation validation detects any entities in tailored output not present in the original resume"
  artifacts:
    - path: "resume_ai/tailor.py"
      provides: "Resume tailoring via Anthropic structured outputs"
      exports: ["tailor_resume"]
      min_lines: 50
    - path: "resume_ai/cover_letter.py"
      provides: "Cover letter generation via Anthropic structured outputs"
      exports: ["generate_cover_letter"]
      min_lines: 40
    - path: "resume_ai/validator.py"
      provides: "Post-generation anti-fabrication validation comparing tailored vs original"
      exports: ["validate_no_fabrication", "ValidationResult"]
      min_lines: 30
  key_links:
    - from: "resume_ai/tailor.py"
      to: "resume_ai/models.py"
      via: "TailoredResume schema for structured output"
      pattern: "from resume_ai\\.models import TailoredResume"
    - from: "resume_ai/tailor.py"
      to: "anthropic"
      via: "client.messages.parse() with output_format"
      pattern: "client\\.messages\\.parse"
    - from: "resume_ai/cover_letter.py"
      to: "resume_ai/models.py"
      via: "CoverLetter schema for structured output"
      pattern: "from resume_ai\\.models import CoverLetter"
    - from: "resume_ai/cover_letter.py"
      to: "anthropic"
      via: "client.messages.parse() with output_format"
      pattern: "client\\.messages\\.parse"
    - from: "resume_ai/validator.py"
      to: "resume_ai/models.py"
      via: "TailoredResume for type hints"
      pattern: "from resume_ai\\.models import TailoredResume"
---

<objective>
Implement the two core AI functions: resume tailoring and cover letter generation, both using Anthropic structured outputs with anti-fabrication guardrails. Also implement post-generation validation (Layer 3 of the anti-fabrication architecture from research) that programmatically compares extracted entities from the tailored output against the original resume.

Purpose: These are the core value-producing functions of Phase 7. The tailor function reorders and emphasizes the user's real experience to match a job description. The cover letter function generates a targeted letter referencing specific company/role details. The validator provides a programmatic safety net that catches any fabricated entities the LLM might introduce despite system prompt constraints. Both LLM functions use temperature=0 (or 0.3 for cover letter) and structured Pydantic output to guarantee valid, schema-compliant responses.

Output: `resume_ai/tailor.py`, `resume_ai/cover_letter.py`, and `resume_ai/validator.py` -- standalone functions callable from dashboard endpoints.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-ai-resume-cover-letter/07-RESEARCH.md
@.planning/phases/07-ai-resume-cover-letter/07-01-SUMMARY.md
@resume_ai/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Resume tailoring with anti-fabrication guardrails</name>
  <files>resume_ai/tailor.py</files>
  <action>
Create `resume_ai/tailor.py` with the resume tailoring function:

1. Define `SYSTEM_PROMPT` constant with the anti-fabrication system prompt from research:
   - Explicitly forbid adding any fact not in the original resume
   - Allow reordering sections, reordering bullet points, rephrasing for clarity
   - Allow adjusting professional summary emphasis
   - Allow reordering skills list by relevance
   - MUST NOT add any skill, technology, company, role, metric, or achievement not in original
   - Keep to 2 pages maximum
   - Use standard ATS-friendly section headers: PROFESSIONAL SUMMARY, TECHNICAL SKILLS, WORK EXPERIENCE, KEY PROJECTS, EDUCATION
   - Expand all acronyms from the job description on first use

2. Implement `tailor_resume(resume_text: str, job_description: str, job_title: str, company_name: str, model: str = "claude-sonnet-4-5-20250929") -> TailoredResume`:
   - Create `Anthropic()` client (reads ANTHROPIC_API_KEY from env automatically)
   - Call `client.messages.parse()` with:
     - model parameter (configurable, default to claude-sonnet-4-5-20250929)
     - max_tokens=4096
     - temperature=0 (critical for anti-fabrication)
     - system=SYSTEM_PROMPT
     - output_format=TailoredResume (from resume_ai.models)
     - messages with user content containing original resume text + job description + title + company
   - Return `response.parsed_output` (a TailoredResume instance)
   - Wrap the Anthropic call in try/except to catch `anthropic.AuthenticationError` and raise a clear error: "ANTHROPIC_API_KEY not set or invalid. Add it to your .env file."
   - Also catch `anthropic.APIError` for general API failures with descriptive message.

3. Add a helper `format_resume_as_text(tailored: TailoredResume) -> str` that converts the structured output back to plain text for diff comparison:
   - Header: "PROFESSIONAL SUMMARY\n\n{summary}\n\n"
   - "TECHNICAL SKILLS\n\n" then each SkillSection as "{category}: {', '.join(skills)}\n"
   - "WORK EXPERIENCE\n\n" then each WorkExperience as "{title} - {company} ({period})\n" with bullet points
   - "KEY PROJECTS\n\n" then each project as "- {project}\n"
   - "EDUCATION\n\n{education}"

4. Follow project conventions: `from __future__ import annotations`, docstrings, type hints.
  </action>
  <verify>
Run: `python -c "from resume_ai.tailor import tailor_resume, format_resume_as_text, SYSTEM_PROMPT; print('Tailor OK'); print(f'Prompt length: {len(SYSTEM_PROMPT)} chars')"` -- importable, system prompt exists.
Run: `python -c "from resume_ai.tailor import format_resume_as_text; from resume_ai.models import TailoredResume, SkillSection, WorkExperience; t = TailoredResume(professional_summary='Test summary', technical_skills=[SkillSection(category='Cloud', skills=['K8s', 'GKE'])], work_experience=[WorkExperience(company='Acme', title='CTO', period='2020-2024', achievements=['Led team'])], key_projects=['Project X'], education='BS CS', tailoring_notes='Test'); txt = format_resume_as_text(t); assert 'PROFESSIONAL SUMMARY' in txt; assert 'Cloud: K8s, GKE' in txt; print('Format OK')"` -- format function produces expected structure.
  </verify>
  <done>
tailor_resume() function callable with resume text and job details. format_resume_as_text() converts TailoredResume back to plain text. System prompt enforces anti-fabrication rules. Temperature fixed at 0. Model is configurable (default Sonnet).
  </done>
</task>

<task type="auto">
  <name>Task 2: Cover letter generation and post-generation anti-fabrication validator</name>
  <files>
    resume_ai/cover_letter.py
    resume_ai/validator.py
  </files>
  <action>
**Part A: Create `resume_ai/cover_letter.py`** with the cover letter generation function:

1. Define `SYSTEM_PROMPT` constant for cover letter generation:
   - ONLY reference achievements, skills, and experience from the provided resume
   - Highlight 2-3 most relevant achievements with specific metrics
   - Reference the company name and specific role
   - Mention open-source contributions if relevant (LangFlow, Kubert)
   - Keep to one page (approximately 300-400 words total)
   - Professional but personable tone
   - Do NOT fabricate any detail not in the resume

2. Implement `generate_cover_letter(resume_text: str, job_description: str, job_title: str, company_name: str, model: str = "claude-sonnet-4-5-20250929") -> CoverLetter`:
   - Create `Anthropic()` client
   - Call `client.messages.parse()` with:
     - model parameter (configurable, default Sonnet)
     - max_tokens=2048
     - temperature=0.3 (slightly higher for natural writing, per research recommendation)
     - system=SYSTEM_PROMPT
     - output_format=CoverLetter (from resume_ai.models)
     - messages with user content containing resume + job description + title + company
   - Return `response.parsed_output`
   - Same error handling as tailor.py: catch AuthenticationError and APIError with clear messages.

3. Add helper `format_cover_letter_as_text(letter: CoverLetter, candidate_name: str) -> str`:
   - Format as: greeting + "\n\n" + opening_paragraph + "\n\n" + "\n\n".join(body_paragraphs) + "\n\n" + closing_paragraph + "\n\n" + sign_off + "\n" + candidate_name
   - This is used for the diff view and for rendering to PDF.

4. Follow project conventions: `from __future__ import annotations`, docstrings, type hints.

**Part B: Create `resume_ai/validator.py`** -- Post-generation anti-fabrication validation (Layer 3 from research):

This is the programmatic safety net that compares extracted entities from the tailored resume against the original to flag any fabricated additions.

1. Define a `ValidationResult` Pydantic model (or dataclass):
   - `is_valid: bool` -- True if no fabricated entities detected
   - `new_companies: list[str]` -- company names in tailored but not in original
   - `new_skills: list[str]` -- technology/skill terms in tailored but not in original
   - `new_metrics: list[str]` -- numeric metrics (percentages, dollar amounts, etc.) in tailored but not in original
   - `warnings: list[str]` -- human-readable warning messages

2. Implement helper `_extract_entities(text: str) -> dict[str, set[str]]`:
   - Extract company-like names: Use regex to find capitalized multi-word sequences (2+ words starting with uppercase) that look like company names. Also extract any word following "at " or "for " patterns.
   - Extract tech/skill terms: Use a set of known tech keywords from the resume domain (Kubernetes, Python, AWS, GCP, Docker, etc.) plus any CamelCase or ALL_CAPS terms. Keep it simple -- regex-based, not NLP.
   - Extract metrics: Use regex to find patterns like percentages (`\d+%`), dollar amounts (`\$[\d,]+`, `USD [\d,]+`), multipliers (`\d+x`), and large numbers (`\d{3,}`).
   - Return `{"companies": set, "skills": set, "metrics": set}`.
   - Normalize all extracted strings to lowercase for comparison.

3. Implement `validate_no_fabrication(original_text: str, tailored_text: str) -> ValidationResult`:
   - Call `_extract_entities()` on both original and tailored text.
   - For each entity type, compute: `new_entities = tailored_entities - original_entities`
   - Build warnings list: one warning per new entity, e.g., "New company detected: 'Acme Corp' not found in original resume"
   - Set `is_valid = True` if all three new_* lists are empty, else `False`.
   - Return `ValidationResult`.

4. Follow project conventions: `from __future__ import annotations`, docstrings, type hints.
  </action>
  <verify>
Run: `python -c "from resume_ai.cover_letter import generate_cover_letter, format_cover_letter_as_text, SYSTEM_PROMPT; print('Cover letter OK'); print(f'Prompt length: {len(SYSTEM_PROMPT)} chars')"` -- importable.
Run: `python -c "from resume_ai.cover_letter import format_cover_letter_as_text; from resume_ai.models import CoverLetter; cl = CoverLetter(greeting='Dear Hiring Manager,', opening_paragraph='I am writing...', body_paragraphs=['Para 1', 'Para 2'], closing_paragraph='Thank you...', sign_off='Sincerely,'); txt = format_cover_letter_as_text(cl, 'Patryk Golabek'); assert 'Dear Hiring Manager,' in txt; assert 'Patryk Golabek' in txt; print('Format OK')"` -- format function works.
Run: `python -c "from resume_ai.validator import validate_no_fabrication, ValidationResult; result = validate_no_fabrication('I worked at Google using Python and Kubernetes. Achieved 50% improvement.', 'I worked at Google and Amazon using Python, Kubernetes, and Rust. Achieved 50% improvement and 200% growth.'); print(f'Valid: {result.is_valid}'); print(f'New companies: {result.new_companies}'); print(f'New skills: {result.new_skills}'); print(f'New metrics: {result.new_metrics}'); assert not result.is_valid; assert len(result.warnings) > 0; print('Validator OK')"` -- validator catches fabricated entities.
Run: `python -c "from resume_ai.validator import validate_no_fabrication; result = validate_no_fabrication('I worked at Google using Python.', 'Using Python, I worked at Google.'); assert result.is_valid; print('No false positives for reordering')"` -- validator does not flag reordering of existing content.
  </verify>
  <done>
generate_cover_letter() callable with resume text and job details. format_cover_letter_as_text() converts CoverLetter to displayable text. Temperature set to 0.3 for natural writing. System prompt enforces factual accuracy from resume only. validate_no_fabrication() compares entities between original and tailored text, returning a ValidationResult with any detected additions -- completing Layer 3 of the anti-fabrication guardrail architecture.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from resume_ai.tailor import tailor_resume"` -- tailor importable
2. `python -c "from resume_ai.cover_letter import generate_cover_letter"` -- cover letter importable
3. `python -c "from resume_ai.validator import validate_no_fabrication, ValidationResult"` -- validator importable
4. Both system prompts contain anti-fabrication instructions
5. format_resume_as_text produces plain text with ATS section headers
6. format_cover_letter_as_text produces formatted letter with candidate name
7. validate_no_fabrication detects fabricated companies, skills, and metrics in tailored output
8. validate_no_fabrication does NOT flag reordering of existing content (no false positives)
</verification>

<success_criteria>
- tailor_resume() uses Anthropic structured outputs with TailoredResume schema
- generate_cover_letter() uses Anthropic structured outputs with CoverLetter schema
- Anti-fabrication guardrails: system prompt constraints + temperature=0 for resume + post-generation validation
- validate_no_fabrication() extracts entities from both texts and flags additions not in original
- Both LLM functions accept configurable model parameter (default claude-sonnet-4-5-20250929)
- Both have clear error handling for missing/invalid API key
- format_resume_as_text() and format_cover_letter_as_text() helpers exist for diff/rendering
</success_criteria>

<output>
After completion, create `.planning/phases/07-ai-resume-cover-letter/07-02-SUMMARY.md`
</output>
