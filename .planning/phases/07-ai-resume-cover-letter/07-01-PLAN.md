---
phase: 07-ai-resume-cover-letter
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - resume_ai/__init__.py
  - resume_ai/models.py
  - resume_ai/extractor.py
  - resume_ai/tracker.py
  - webapp/db.py
autonomous: true
user_setup:
  - service: anthropic
    why: "LLM API for resume tailoring and cover letter generation"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "https://console.anthropic.com/settings/keys -> Create Key"
    dashboard_config: []

must_haves:
  truths:
    - "PDF text extraction produces structured Markdown from the user's resume"
    - "Pydantic models define the exact LLM output schema for resume and cover letter"
    - "Resume version metadata is persisted in SQLite"
    - "New dependencies (anthropic, pymupdf4llm, weasyprint) are installable"
  artifacts:
    - path: "resume_ai/__init__.py"
      provides: "Package marker"
    - path: "resume_ai/models.py"
      provides: "TailoredResume, CoverLetter, SkillSection, WorkExperience Pydantic models"
      exports: ["TailoredResume", "CoverLetter", "SkillSection", "WorkExperience"]
    - path: "resume_ai/extractor.py"
      provides: "PDF text extraction as Markdown"
      exports: ["extract_resume_text"]
    - path: "resume_ai/tracker.py"
      provides: "Resume version CRUD (save, get by job, get all)"
      exports: ["save_resume_version", "get_resume_versions", "get_versions_for_job"]
    - path: "webapp/db.py"
      provides: "Schema migration v6 with resume_versions table"
      contains: "CREATE TABLE IF NOT EXISTS resume_versions"
    - path: "pyproject.toml"
      provides: "Updated dependencies"
      contains: "anthropic"
  key_links:
    - from: "resume_ai/tracker.py"
      to: "webapp/db.py"
      via: "get_conn() for database access"
      pattern: "from webapp.db import get_conn"
    - from: "resume_ai/extractor.py"
      to: "pymupdf4llm"
      via: "pymupdf4llm.to_markdown()"
      pattern: "pymupdf4llm\\.to_markdown"
---

<objective>
Create the foundation for the AI resume module: install dependencies, define structured output models for LLM responses, implement PDF text extraction, and add the resume_versions SQLite table for tracking.

Purpose: Establishes the data layer and extraction pipeline that all other Phase 7 plans depend on. Without these models, the LLM calls cannot produce structured output. Without the tracker, versions cannot be persisted.

Output: `resume_ai/` package with models.py, extractor.py, tracker.py; updated db.py with migration v6; updated pyproject.toml with new deps.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-ai-resume-cover-letter/07-RESEARCH.md
@config.py
@webapp/db.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Dependencies, package structure, and Pydantic models</name>
  <files>
    pyproject.toml
    resume_ai/__init__.py
    resume_ai/models.py
    resume_ai/extractor.py
  </files>
  <action>
1. Update `pyproject.toml` dependencies to add:
   - `anthropic>=0.79.0`
   - `pymupdf4llm>=0.2.9`
   - `weasyprint>=68.0`

   Also add `resume_ai` to `[tool.hatch.build.targets.wheel]` packages list.

2. Create `resume_ai/__init__.py` -- empty file, package marker.

3. Create `resume_ai/models.py` with Pydantic v2 models matching the structured output schemas from research:
   - `SkillSection(BaseModel)`: category (str), skills (list[str])
   - `WorkExperience(BaseModel)`: company (str), title (str), period (str), achievements (list[str] -- with Field description noting reorder-only)
   - `TailoredResume(BaseModel)`: professional_summary (str), technical_skills (list[SkillSection]), work_experience (list[WorkExperience]), key_projects (list[str]), education (str), tailoring_notes (str -- explanation of what changed and why)
   - `CoverLetter(BaseModel)`: greeting (str), opening_paragraph (str), body_paragraphs (list[str] -- 2-3 paragraphs), closing_paragraph (str), sign_off (str)
   - Use `from __future__ import annotations` at top.
   - Add `Field(description=...)` on each field for LLM guidance.
   - Follow existing project conventions: pydantic v2, snake_case, docstrings.

4. Create `resume_ai/extractor.py`:
   - Function `extract_resume_text(pdf_path: str | Path) -> str` that calls `pymupdf4llm.to_markdown(str(pdf_path))` and returns the Markdown string.
   - Accept both str and Path, convert to str before passing to pymupdf4llm.
   - Add a module docstring explaining purpose.
   - If the file doesn't exist, raise FileNotFoundError with a clear message including the path.
  </action>
  <verify>
Run: `python -c "from resume_ai.models import TailoredResume, CoverLetter, SkillSection, WorkExperience; print('Models OK')"` succeeds.
Run: `python -c "from resume_ai.extractor import extract_resume_text; print('Extractor OK')"` succeeds.
Run: `pip install -e .` or `pip install anthropic pymupdf4llm weasyprint` completes without errors.
  </verify>
  <done>
All four Pydantic models importable. extract_resume_text function importable. Dependencies in pyproject.toml. resume_ai package exists.
  </done>
</task>

<task type="auto">
  <name>Task 2: Resume version tracker with SQLite migration</name>
  <files>
    webapp/db.py
    resume_ai/tracker.py
  </files>
  <action>
1. In `webapp/db.py`:
   - Bump `SCHEMA_VERSION` from 5 to 6.
   - Add migration 6 to `MIGRATIONS` dict:
     ```sql
     CREATE TABLE IF NOT EXISTS resume_versions (
         id INTEGER PRIMARY KEY AUTOINCREMENT,
         job_dedup_key TEXT NOT NULL,
         resume_type TEXT NOT NULL,  -- 'resume' or 'cover_letter'
         file_path TEXT NOT NULL,
         original_resume_path TEXT NOT NULL,
         model_used TEXT NOT NULL,
         prompt_hash TEXT,
         created_at TEXT NOT NULL DEFAULT (datetime('now')),
         FOREIGN KEY (job_dedup_key) REFERENCES jobs(dedup_key)
     );
     ```
   - Add index: `CREATE INDEX IF NOT EXISTS idx_resume_versions_job ON resume_versions(job_dedup_key)`

2. Create `resume_ai/tracker.py`:
   - Import `get_conn` from `webapp.db`.
   - `save_resume_version(job_dedup_key: str, resume_type: str, file_path: str, original_resume_path: str, model_used: str, prompt_hash: str | None = None) -> int`:
     INSERT into resume_versions, return the new row id.
   - `get_versions_for_job(job_dedup_key: str) -> list[dict]`:
     SELECT * WHERE job_dedup_key = ? ORDER BY created_at DESC, return list of dicts.
   - `get_all_versions(limit: int = 100) -> list[dict]`:
     SELECT rv.*, j.title, j.company FROM resume_versions rv LEFT JOIN jobs j ON rv.job_dedup_key = j.dedup_key ORDER BY rv.created_at DESC LIMIT ?, return list of dicts.
   - Follow project conventions: `from __future__ import annotations`, docstrings, snake_case.
  </action>
  <verify>
Run: `python -c "from webapp.db import get_conn, SCHEMA_VERSION; assert SCHEMA_VERSION == 6; print('Schema v6 OK')"` succeeds.
Run: `python -c "from resume_ai.tracker import save_resume_version, get_versions_for_job, get_all_versions; print('Tracker OK')"` succeeds.
Start the webapp briefly to verify migration runs: `JOBFLOW_TEST_DB=1 python -c "from webapp.db import init_db; init_db(); print('Migration OK')"`.
  </verify>
  <done>
resume_versions table created via migration v6. Tracker functions importable and functional. Migration is idempotent (safe to re-run).
  </done>
</task>

</tasks>

<verification>
1. `python -c "from resume_ai.models import TailoredResume, CoverLetter"` -- models importable
2. `python -c "from resume_ai.extractor import extract_resume_text"` -- extractor importable
3. `python -c "from resume_ai.tracker import save_resume_version"` -- tracker importable
4. `JOBFLOW_TEST_DB=1 python -c "from webapp.db import init_db, get_conn; init_db(); c = get_conn(); c.execute('SELECT * FROM resume_versions LIMIT 1'); print('Table exists')"` -- migration ran
5. `pip install anthropic pymupdf4llm weasyprint` -- deps install cleanly
</verification>

<success_criteria>
- resume_ai/ package exists with __init__.py, models.py, extractor.py, tracker.py
- Four Pydantic models defined with Field descriptions for LLM guidance
- extract_resume_text() callable with a PDF path
- resume_versions SQLite table created via idempotent migration v6
- Tracker CRUD functions (save, get_for_job, get_all) implemented
- pyproject.toml updated with anthropic, pymupdf4llm, weasyprint
</success_criteria>

<output>
After completion, create `.planning/phases/07-ai-resume-cover-letter/07-01-SUMMARY.md`
</output>
