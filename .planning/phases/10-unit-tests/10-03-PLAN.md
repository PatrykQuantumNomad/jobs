---
phase: 10-unit-tests
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/test_dedup.py
  - tests/resume_ai/test_validator.py
  - tests/test_delta.py
autonomous: true

must_haves:
  truths:
    - "Exact dedup merges jobs with identical dedup_key() and keeps the more recent/detailed posting"
    - "Fuzzy dedup merges company name variants (Inc/LLC/Corp/Ltd suffixes, spacing, case) within same-title groups"
    - "_normalize_company() strips all corporate suffixes in the documented list and handles trailing commas"
    - "fuzzy_deduplicate([]) returns empty list without error"
    - "Anti-fabrication validator detects new companies, skills, and metrics added by LLM that were not in the original"
    - "Identical original and tailored text produces is_valid=True with empty fabrication lists"
    - "_extract_entities() extracts multi-word capitalized companies, 'at/for' patterns, known tech keywords, CamelCase terms, ALL_CAPS acronyms, and numeric metrics"
    - "Delta detection removes stale jobs from searched platforms whose last_seen_at predates the run timestamp"
    - "Delta detection preserves jobs from unsearched platforms even if their last_seen_at is old"
    - "New jobs get first_seen_at and last_seen_at timestamps on insert"
  artifacts:
    - path: "tests/test_dedup.py"
      provides: "UNIT-05 and UNIT-06: Exact and fuzzy deduplication tests"
      contains: "class TestExactDedup"
    - path: "tests/resume_ai/test_validator.py"
      provides: "UNIT-07: Anti-fabrication validation tests"
      contains: "class TestAntiFabrication"
    - path: "tests/test_delta.py"
      provides: "UNIT-08: Delta detection tests"
      contains: "class TestDeltaDetection"
  key_links:
    - from: "tests/test_dedup.py"
      to: "dedup.py"
      via: "Import of fuzzy_deduplicate, _normalize_company"
      pattern: "from dedup import"
    - from: "tests/resume_ai/test_validator.py"
      to: "resume_ai/validator.py"
      via: "Import of validate_no_fabrication, _extract_entities"
      pattern: "from resume_ai.validator import"
    - from: "tests/test_delta.py"
      to: "webapp/db.py"
      via: "Import of upsert_job, remove_stale_jobs, get_job"
      pattern: "import webapp.db as db_module"
---

<objective>
Write unit tests for deduplication (UNIT-05, UNIT-06), anti-fabrication validation (UNIT-07), and delta detection (UNIT-08).

Purpose: These three modules complete the pure-logic unit test coverage for Phase 10. Dedup tests verify the two-pass algorithm (exact + fuzzy). Validator tests verify entity extraction heuristics and fabrication detection. Delta tests verify the temporal job tracking logic using the in-memory DB fixture.

Output: tests/test_dedup.py, tests/resume_ai/test_validator.py, and tests/test_delta.py.
</objective>

<execution_context>
@/Users/patrykattc/.claude/get-shit-done/workflows/execute-plan.md
@/Users/patrykattc/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-unit-tests/10-RESEARCH.md
@dedup.py
@resume_ai/validator.py
@webapp/db.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create tests/test_dedup.py for UNIT-05 and UNIT-06</name>
  <files>tests/test_dedup.py</files>
  <action>
Create unit tests for exact and fuzzy deduplication. Mark all tests with `@pytest.mark.unit`.

Create a module-level helper:

```python
from models import Job
from dedup import fuzzy_deduplicate, _normalize_company


def _make_job(company, title, platform="indeed", **kwargs):
    """Build a Job with minimal required fields for dedup tests."""
    defaults = {
        "url": f"https://example.com/{company.lower().replace(' ', '-')}",
    }
    defaults.update(kwargs)
    return Job(platform=platform, title=title, company=company, **defaults)
```

**class TestNormalizeCompany:**

Parametrize `(input_name, expected)`:
- `("Google Inc.", "google")`
- `("Google Inc", "google")`
- `("Google LLC", "google")`
- `("Google Ltd.", "google")`
- `("Google Ltd", "google")`
- `("Google Corp.", "google")`
- `("Google Corp", "google")`
- `("Google Corporation", "google")`
- `("Google Incorporated", "google")`
- `("Google Company", "google")`
- `("Google Co.", "google")`
- `("GOOGLE", "google")` -- case only
- `("  Google  ", "google")` -- whitespace
- `("Google,", "google")` -- trailing comma
- `("Acme", "acme")` -- no suffix

**class TestExactDedup:**
- `test_identical_jobs_dedup_to_one`: Two jobs with same company+title -> 1 result
- `test_different_titles_not_deduped`: Same company, different titles -> 2 results
- `test_different_companies_not_deduped`: Different companies, same title -> 2 results
- `test_case_insensitive`: "Google" vs "google" same title -> 1 result
- `test_inc_suffix_stripped`: "Google Inc." vs "Google" same title -> 1 result (dedup_key strips " inc.")
- `test_winner_has_more_recent_date`: Two duplicates with different posted_date -> winner is the more recent
- `test_winner_has_longer_description`: Same date, different description lengths -> winner is the longer
- `test_alias_recorded`: When two companies merge, the loser's name appears in winner.company_aliases
- `test_empty_list`: `fuzzy_deduplicate([])` -> `[]`
- `test_single_job`: `fuzzy_deduplicate([job])` -> `[job]`

**class TestFuzzyDedup:**
- `test_llc_vs_inc_merges`: "Google LLC" and "Google Inc." with same title -> 1 result (suffix stripping makes them identical in Pass 2)
- `test_corp_variants_merge`: "Acme Corp." and "Acme Corporation" same title -> 1 result
- `test_co_variant_merges`: "Tech Co." and "Tech Company" same title -> 1 result
- `test_completely_different_companies_not_merged`: "Google" and "Microsoft" same title -> 2 results (fuzzy score well below 90)
- `test_three_way_merge`: "Google Inc", "Google LLC", "Google Corp" all same title -> 1 result with 2 aliases
- `test_cross_platform_dedup`: Same company+title from "indeed" and "dice" -> 1 result (cross-platform merge)
- `test_fuzzy_aliases_sorted`: After fuzzy merge, company_aliases list is sorted alphabetically

**Important note on dedup_key vs _normalize_company difference:** `dedup_key()` (models.py) strips: `" inc."`, `" inc"`, `" llc"`, `" ltd"`, `","`. `_normalize_company()` (dedup.py) strips a LONGER list including `" incorporated"`, `" corporation"`, `" company"`, `" corp."`, `" corp"`, `" co."`. So "Google Corp" deduplicates in fuzzy Pass 2 but NOT in exact Pass 1. Include a test proving this:

- `test_corp_not_in_exact_pass`: Two jobs: "Google Corp" and "Google" same title -- after dedup, exactly 1 result (fuzzy pass merges them even though exact pass keeps both)
  </action>
  <verify>
Run: `uv run pytest tests/test_dedup.py -v --tb=short` -- all tests pass.
Run: `uv run pytest tests/test_dedup.py -v --tb=short 2>&1 | grep -c "PASSED"` -- expect 25+ passed tests.
  </verify>
  <done>tests/test_dedup.py covers: _normalize_company() with 15+ parametrized suffix/case/whitespace cases, exact dedup (identical keys, winner selection by date/description, alias recording, empty/single input), fuzzy dedup (LLC/Inc/Corp/Co variants, cross-platform, three-way merge, sorted aliases), and the exact vs fuzzy pass boundary (Corp not stripped in Pass 1 but merged in Pass 2). All tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: Create tests/resume_ai/test_validator.py for UNIT-07</name>
  <files>tests/resume_ai/test_validator.py</files>
  <action>
Create unit tests for the anti-fabrication validator. Mark all tests with `@pytest.mark.unit`.

**IMPORTANT: Use realistic resume text for entity extraction.** The regex heuristics need multi-word capitalized sequences for companies, and known tech keywords or CamelCase/ALL_CAPS for skills. Short contrived strings may not trigger the patterns.

**class TestExtractEntities:**

Test the private `_extract_entities()` function directly for diagnosability.

Companies:
- `test_multi_word_company`: Text "Worked at Translucent Computing for 5 years" -> "translucent computing" in companies set
- `test_at_pattern_single_word`: Text "Worked at Google for 3 years" -> "google" in companies set (matched by "at Google" pattern)
- `test_stop_words_filtered`: Text "Led Built Managed" -> none of these are extracted as companies
- `test_for_pattern`: Text "Developed for Stripe Solutions" -> "stripe solutions" in companies set

Skills:
- `test_known_keywords`: Text "Experience with python, kubernetes, and terraform" -> {"python", "kubernetes", "terraform"} subset of skills
- `test_camelcase`: Text "Built APIs with FastAPI and LangGraph" -> "fastapi" and "langgraph" in skills
- `test_allcaps_acronyms`: Text "Deployed to AWS, GKE, and EKS" -> "aws", "gke", "eks" in skills
- `test_empty_text`: Text "" -> all sets empty

Metrics:
- `test_percentages`: Text "Achieved 50% improvement and 200% growth" -> "50%" and "200%" in metrics
- `test_dollar_amounts`: Text "Saved $1.2M and managed $200,000 budget" -> both in metrics
- `test_multipliers`: Text "Achieved 10x performance improvement" -> "10x" in metrics
- `test_large_numbers`: Text "Processed 500 million records across 1000 nodes" -> "500" and "1000" in metrics

**class TestAntiFabrication:**

Test the public `validate_no_fabrication()` function.

- `test_identical_text_is_valid`: Same text for both original and tailored -> `is_valid=True`, all lists empty
- `test_empty_texts_valid`: Both empty strings -> `is_valid=True`
- `test_new_company_detected`: Original: "Worked at Translucent Computing" -- Tailored adds "and at Stripe" -> `is_valid=False`, "stripe" in new_companies (Note: single word "Stripe" detected by "at Stripe" pattern)
- `test_new_skill_detected`: Original: "Experience with Python and Kubernetes" -- Tailored adds "and Terraform" -> `is_valid=False`, "terraform" in new_skills
- `test_new_metric_detected`: Original: "Achieved 50% improvement" -- Tailored adds "and 300% growth" -> `is_valid=False`, "300%" in new_metrics
- `test_warnings_generated`: When fabrications detected, warnings list is non-empty and each warning is human-readable
- `test_skill_in_original_not_flagged`: Original has "python", tailored also has "python" -> NOT flagged as new
- `test_reordered_text_valid`: Same entities in different order -> `is_valid=True`
- `test_multiple_fabrication_types`: Tailored adds new company + new skill + new metric -> all three lists populated, `is_valid=False`

**class TestValidationResult:**

- `test_result_is_pydantic_model`: Verify `ValidationResult` is a Pydantic BaseModel
- `test_result_default_values`: `ValidationResult()` -> `is_valid=True`, all lists empty (since default `is_valid` is True from field default... actually, check the model: `is_valid: bool` has no default -- it's a required field. Construct with `is_valid=True` explicitly)
  </action>
  <verify>
Run: `uv run pytest tests/resume_ai/test_validator.py -v --tb=short` -- all tests pass.
Run: `uv run pytest tests/resume_ai/test_validator.py -v --tb=short 2>&1 | grep -c "PASSED"` -- expect 18+ passed tests.
  </verify>
  <done>tests/resume_ai/test_validator.py covers: _extract_entities() for companies (multi-word, at/for patterns, stop word filtering), skills (known keywords, CamelCase, ALL_CAPS), metrics (percentages, dollars, multipliers, large numbers); validate_no_fabrication() for identical text, new companies/skills/metrics detection, warnings generation, reordering tolerance. All tests pass.</done>
</task>

<task type="auto">
  <name>Task 3: Create tests/test_delta.py for UNIT-08</name>
  <files>tests/test_delta.py</files>
  <action>
Create unit tests for delta detection logic. Mark all tests with `@pytest.mark.unit`.

These tests use the `_fresh_db` autouse fixture for in-memory SQLite isolation. Import `webapp.db` as `db_module` and use `upsert_job()`, `get_job()`, `remove_stale_jobs()` directly.

**IMPORTANT on timestamps:** Use explicitly different timestamps with a clear time gap to avoid flaky tests. Do NOT rely on `datetime.now()` being different between sequential calls. Instead, construct ISO timestamps manually: `"2026-01-01T00:00:00"` vs `"2026-02-01T00:00:00"`.

To control `last_seen_at`, note that `upsert_job()` sets `last_seen_at = datetime.now()`. To test stale detection, you need to update `last_seen_at` manually after insert:

```python
def _set_last_seen(dedup_key: str, timestamp: str):
    """Override last_seen_at for a job (test helper)."""
    conn = db_module.get_conn()
    conn.execute(
        "UPDATE jobs SET last_seen_at = ? WHERE dedup_key = ?",
        (timestamp, dedup_key),
    )
    conn.commit()
```

**class TestNewJobTimestamps:**
- `test_new_job_gets_first_seen_at`: Insert a job via upsert_job -> get_job() -> `first_seen_at` is not None
- `test_new_job_gets_last_seen_at`: Insert a job -> `last_seen_at` is not None
- `test_first_seen_preserved_on_update`: Insert job, note first_seen_at. Upsert same dedup_key again -> first_seen_at unchanged (ON CONFLICT keeps original)
- `test_last_seen_updated_on_re_upsert`: Insert job, set last_seen_at to old time. Upsert same key again -> last_seen_at is now newer than old time

**class TestRemoveStaleJobs:**
- `test_stale_job_removed`: Insert an indeed job, set its last_seen_at to "2026-01-01T00:00:00". Call `remove_stale_jobs(["indeed"], "2026-02-01T00:00:00")` -> returns 1, `get_job()` returns None
- `test_fresh_job_not_removed`: Insert an indeed job, set its last_seen_at to "2026-02-01T00:00:00". Call `remove_stale_jobs(["indeed"], "2026-01-15T00:00:00")` -> returns 0, job still exists
- `test_unsearched_platform_preserved`: Insert a dice job, set last_seen_at to old time. Call `remove_stale_jobs(["indeed"], "2026-02-01T00:00:00")` (only indeed searched) -> returns 0, dice job still exists
- `test_empty_platforms_removes_nothing`: `remove_stale_jobs([], "2026-02-01T00:00:00")` -> returns 0
- `test_multiple_platforms_searched`: Insert one indeed job (stale) and one dice job (stale). Call `remove_stale_jobs(["indeed", "dice"], "2026-02-01T00:00:00")` -> returns 2
- `test_mixed_fresh_and_stale`: Insert 3 indeed jobs. Set 2 as stale, keep 1 fresh. Call remove_stale_jobs -> returns 2, fresh one remains

**class TestDeltaDetectionFlow:**
- `test_full_delta_cycle`: Simulate a realistic delta detection flow:
  1. First run: insert 3 jobs, all get first_seen_at and last_seen_at
  2. Second run: re-upsert 2 of the 3 jobs (simulates them still being listed). Set the 3rd job's last_seen_at to an old timestamp.
  3. Call remove_stale_jobs with the 2nd run's timestamp
  4. Verify: 2 jobs remain, 1 removed. The 2 remaining have updated last_seen_at. Their first_seen_at is preserved from the first run.
  </action>
  <verify>
Run: `uv run pytest tests/test_delta.py -v --tb=short` -- all tests pass.
Run: `uv run pytest tests/test_delta.py -v --tb=short 2>&1 | grep -c "PASSED"` -- expect 10+ passed tests.
  </verify>
  <done>tests/test_delta.py covers: timestamp assignment on new jobs (first_seen_at, last_seen_at), timestamp preservation on re-upsert, stale job removal (stale removed, fresh kept, unsearched platform preserved, empty platforms no-op, multi-platform, mixed), and a full delta detection cycle simulating two pipeline runs. All tests use explicit timestamps to avoid flakiness.</done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_dedup.py tests/resume_ai/test_validator.py tests/test_delta.py -v --tb=short` -- all tests pass
2. `uv run pytest tests/test_dedup.py tests/resume_ai/test_validator.py tests/test_delta.py -m unit -v` -- markers correct
3. `uv run pytest tests/test_dedup.py --cov=dedup --cov-report=term-missing -q` -- meaningful dedup.py coverage
4. `uv run pytest tests/resume_ai/test_validator.py --cov=resume_ai.validator --cov-report=term-missing -q` -- meaningful validator coverage
5. `uv run pytest tests/test_smoke.py -v --tb=short` -- no regressions
6. `ls job_pipeline/jobs.db 2>/dev/null` -- must NOT exist (in-memory DB only)
</verification>

<success_criteria>
- tests/test_dedup.py covers _normalize_company (15+ suffix variants), exact dedup (identity, winner selection, aliases), fuzzy dedup (LLC/Inc/Corp/Co merging, cross-platform, sorted aliases), and exact vs fuzzy boundary
- tests/resume_ai/test_validator.py covers _extract_entities (companies, skills, metrics extraction) and validate_no_fabrication (identical, new entities, warnings, reordering tolerance)
- tests/test_delta.py covers timestamp assignment, stale removal (searched vs unsearched platforms, empty platforms, mixed), and full delta cycle
- All tests pass with `uv run pytest tests/test_dedup.py tests/resume_ai/test_validator.py tests/test_delta.py -v`
- All tests marked @pytest.mark.unit
- Delta tests use explicit timestamps (no flakiness from datetime.now())
</success_criteria>

<output>
After completion, create `.planning/phases/10-unit-tests/10-03-SUMMARY.md`
</output>
