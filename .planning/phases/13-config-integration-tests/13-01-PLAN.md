---
phase: 13-config-integration-tests
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/test_config.py
autonomous: true

must_haves:
  truths:
    - "A valid YAML config loads and all settings are accessible with correct types"
    - "Invalid config values (bad URLs, wrong types, missing required fields) produce clear ValidationError, not silent failures"
    - "Optional fields omitted from YAML get their documented default values"
    - "Environment variables override YAML values following pydantic-settings source precedence"
    - "Helper methods (get_search_queries, enabled_platforms, validate_platform_credentials, build_candidate_profile) work correctly on loaded config"
  artifacts:
    - path: "tests/test_config.py"
      provides: "All config integration tests (CFG-01 through CFG-04)"
      contains: "class TestConfigLoading"
  key_links:
    - from: "tests/test_config.py"
      to: "config.py"
      via: "AppSettings, get_settings, reset_settings imports"
      pattern: "from config import"
    - from: "tests/test_config.py"
      to: "apply_engine/config.py"
      via: "ApplyConfig validation tested through AppSettings"
      pattern: "apply.*default_mode"
---

<objective>
Write all config integration tests (CFG-01 through CFG-04) in a single test file covering YAML loading, validation rejection, defaults, and env var overrides.

Purpose: Prove that config.py correctly loads YAML, validates inputs, applies defaults, and respects source precedence -- the foundation that every other module depends on.
Output: `tests/test_config.py` with ~30-40 tests across 4 test classes.
</objective>

<execution_context>
@/Users/patrykattc/.claude/get-shit-done/workflows/execute-plan.md
@/Users/patrykattc/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-config-integration-tests/13-RESEARCH.md
@config.py
@apply_engine/config.py
@tests/conftest.py
@tests/fixtures/test_config.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Config isolation fixture + YAML loading and validation tests (CFG-01, CFG-02)</name>
  <files>tests/test_config.py</files>
  <action>
Create `tests/test_config.py` with a `config_from_yaml` fixture and two test classes.

**Module-level setup:**
- Import `pytest`, `yaml`, `json`, `ValidationError` from pydantic
- Import `AppSettings`, `reset_settings` from `config`
- Import sub-models needed for direct validation tests: `ScoringWeights`, `SearchQueryConfig`, `ScheduleConfig` from `config`, `ApplyConfig` from `apply_engine.config`

**`config_from_yaml` fixture (module-scope helper, NOT autouse):**
```python
@pytest.fixture
def config_from_yaml(tmp_path):
    """Load AppSettings from a temp YAML, isolated from real .env."""
    original_yaml = AppSettings.model_config.get("yaml_file")
    original_env = AppSettings.model_config.get("env_file")

    def _load(yaml_data: dict) -> AppSettings:
        yaml_path = tmp_path / "test.yaml"
        yaml_path.write_text(yaml.dump(yaml_data))
        reset_settings()
        AppSettings.model_config["yaml_file"] = str(yaml_path)
        AppSettings.model_config["env_file"] = "/dev/null"
        return AppSettings()

    yield _load

    AppSettings.model_config["yaml_file"] = original_yaml
    AppSettings.model_config["env_file"] = original_env
    reset_settings()
```

**MINIMAL_YAML constant** (module-level, used across all tests):
```python
MINIMAL_YAML = {
    "search": {"queries": [{"title": "test engineer"}]},
    "scoring": {"target_titles": ["Senior Engineer"], "tech_keywords": ["python"]},
}
```

**FULL_YAML constant** (module-level, richer config for loading tests):
```python
FULL_YAML = {
    "search": {
        "min_salary": 180000,
        "queries": [
            {"title": "Staff Engineer", "keywords": ["kubernetes", "cloud"], "max_pages": 3},
            {"title": "DevOps Lead", "platforms": ["indeed"]},
        ],
    },
    "scoring": {
        "target_titles": ["Staff Engineer", "Principal Engineer"],
        "tech_keywords": ["python", "kubernetes", "terraform"],
        "weights": {"title_match": 3.0, "tech_overlap": 2.5, "remote": 1.0, "salary": 0.5},
    },
    "platforms": {
        "indeed": {"enabled": True},
        "dice": {"enabled": False},
        "remoteok": {"enabled": True},
    },
    "timing": {
        "nav_delay_min": 1.0,
        "nav_delay_max": 3.0,
        "form_delay_min": 0.5,
        "form_delay_max": 1.5,
        "page_load_timeout": 15000,
    },
    "schedule": {"enabled": True, "hour": 9, "minute": 30, "weekdays": [1, 2, 3, 4, 5]},
    "apply": {
        "default_mode": "easy_apply_only",
        "confirm_before_submit": False,
        "max_concurrent_applies": 3,
    },
}
```

**Class 1: `TestConfigLoading` (CFG-01)** -- mark `@pytest.mark.integration`:
1. `test_full_yaml_loads_all_sections` -- load FULL_YAML, assert search.min_salary == 180000, scoring.weights.title_match == 3.0, platforms.dice.enabled is False, timing.nav_delay_min == 1.0, schedule.enabled is True, schedule.weekdays == [1,2,3,4,5], apply.default_mode == "easy_apply_only"
2. `test_search_queries_parsed_correctly` -- load FULL_YAML, assert len(settings.search.queries) == 2, first query title == "Staff Engineer", first query keywords == ["kubernetes", "cloud"], first query max_pages == 3
3. `test_scoring_weights_typed_correctly` -- load FULL_YAML, assert all weight fields are float type, check exact values
4. `test_get_search_queries_filters_by_platform` -- load FULL_YAML, call get_search_queries("indeed") → 2 queries (both match, second is indeed-only), call get_search_queries("dice") → 1 query (only "Staff Engineer" has no platform filter)
5. `test_enabled_platforms_returns_correct_list` -- load FULL_YAML, assert enabled_platforms() returns ["indeed", "remoteok"] (dice disabled)
6. `test_validate_platform_credentials` -- load MINIMAL_YAML, assert indeed → True (session auth), remoteok → True (public), dice → False (no creds set in /dev/null env)
7. `test_build_candidate_profile_returns_model` -- load MINIMAL_YAML, call build_candidate_profile(), assert it returns a CandidateProfile with target_titles == ["Senior Engineer"] and tech_keywords == ["python"]
8. `test_get_settings_singleton_caches` -- use get_settings with test_config.yaml path, call twice, assert same object identity (use `is` comparison). Must call reset_settings() first and set model_config properly.
9. `test_extra_yaml_keys_ignored` -- load MINIMAL_YAML + {"unknown_section": {"foo": "bar"}}, assert no error raised (extra="ignore" in model_config)

**Class 2: `TestConfigValidation` (CFG-02)** -- mark `@pytest.mark.integration`:
1. `test_empty_yaml_missing_required_fields` -- load {}, assert ValidationError with "search" and "scoring" in error locations
2. `test_missing_scoring_section` -- load {"search": {"queries": [{"title": "x"}]}}, assert ValidationError with "scoring" in loc
3. `test_invalid_type_min_salary` -- load MINIMAL_YAML with search.min_salary = "not-a-number", assert ValidationError with type "int_parsing" at loc ("search", "min_salary")
4. Parametrized sub-model validation tests using `@pytest.mark.parametrize`:
   - `ScoringWeights(title_match=-1.0)` → ValidationError (ge=0 constraint)
   - `SearchQueryConfig(title="test", max_pages=99)` → ValidationError (le=10 constraint)
   - `SearchQueryConfig(title="test", max_pages=0)` → ValidationError (ge=1 constraint)
   - `ScheduleConfig(weekdays=[7])` → ValidationError (custom validator: 0-6)
   - `ScheduleConfig(hour=25)` → ValidationError (le=23 constraint)
   - `ApplyConfig(max_concurrent_applies=10)` → ValidationError (le=5)
   - `ApplyConfig(max_concurrent_applies=0)` → ValidationError (ge=1)
   - `ApplyConfig(default_mode="yolo")` → ValidationError (invalid enum)
   - `ApplyConfig(ats_form_fill_timeout=5)` → ValidationError (ge=10)
   - `ApplyConfig(ats_form_fill_timeout=999)` → ValidationError (le=600)
   Name each parametrize ID explicitly (e.g., "negative-weight", "max-pages-too-high", etc.)
5. `test_missing_yaml_file_raises_validation_error` -- point yaml_file to a non-existent path, assert ValidationError for missing required fields (NOT FileNotFoundError). Use reset_settings() + set model_config to "/tmp/does_not_exist.yaml" + "/dev/null" for env_file.
  </action>
  <verify>
Run: `python -m pytest tests/test_config.py::TestConfigLoading tests/test_config.py::TestConfigValidation -v`
All tests pass. No warnings about config leakage.
  </verify>
  <done>
CFG-01: Full YAML loads with correct types, helper methods work, singleton caches, extra keys ignored.
CFG-02: Missing required fields, wrong types, out-of-range values, invalid enums all produce clear ValidationError. Missing YAML file handled correctly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Defaults and env var override tests (CFG-03, CFG-04)</name>
  <files>tests/test_config.py</files>
  <action>
Add two more test classes to `tests/test_config.py`.

**Class 3: `TestConfigDefaults` (CFG-03)** -- mark `@pytest.mark.integration`:
1. `test_minimal_yaml_gets_all_defaults` -- load MINIMAL_YAML (only search.queries + scoring required fields), assert ALL defaults:
   - search.min_salary == 150_000
   - platforms.indeed.enabled is True
   - platforms.dice.enabled is True
   - platforms.remoteok.enabled is True
   - timing.nav_delay_min == 2.0
   - timing.nav_delay_max == 5.0
   - timing.form_delay_min == 1.0
   - timing.form_delay_max == 2.0
   - timing.page_load_timeout == 30_000
   - schedule.enabled is False
   - schedule.hour == 8
   - schedule.minute == 0
   - schedule.weekdays is None
   - scoring.weights.title_match == 2.0
   - scoring.weights.tech_overlap == 2.0
   - scoring.weights.remote == 1.0
   - scoring.weights.salary == 1.0
   - apply.default_mode == "semi_auto" (or ApplyMode.SEMI_AUTO)
   - apply.confirm_before_submit is True
   - apply.max_concurrent_applies == 1
   - apply.screenshot_before_submit is True
   - apply.headed_mode is True
   - apply.ats_form_fill_enabled is True
   - apply.ats_form_fill_timeout == 120
2. `test_credential_defaults_are_none_or_empty` -- load MINIMAL_YAML, assert:
   - indeed_email is None
   - dice_email is None
   - dice_password is None
   - candidate_first_name == ""
   - candidate_desired_salary_usd == 200_000
   - candidate_resume_path == "resumes/Patryk_Golabek_Resume.pdf"
3. `test_partial_section_gets_remaining_defaults` -- load MINIMAL_YAML + timing with only nav_delay_min=0.5, assert nav_delay_min == 0.5, nav_delay_max == 5.0 (default), form_delay_min == 1.0 (default), etc.
4. `test_search_query_defaults` -- load MINIMAL_YAML (query has only title), assert first query: keywords == [], location == "", max_pages == 5, platforms == []

**Class 4: `TestConfigEnvOverrides` (CFG-04)** -- mark `@pytest.mark.integration`:
1. `test_top_level_env_overrides_default` -- monkeypatch.setenv("CANDIDATE_DESIRED_SALARY_USD", "300000"), load MINIMAL_YAML, assert candidate_desired_salary_usd == 300_000
2. `test_credential_env_overrides` -- monkeypatch.setenv for DICE_EMAIL="test@test.com" and DICE_PASSWORD="secret", load MINIMAL_YAML, assert dice_email == "test@test.com" and dice_password == "secret"
3. `test_json_env_overrides_nested_section` -- monkeypatch.setenv("TIMING", json.dumps({"nav_delay_min": 99.0, "nav_delay_max": 99.0, "form_delay_min": 99.0, "form_delay_max": 99.0, "page_load_timeout": 99000})), load MINIMAL_YAML, assert timing.nav_delay_min == 99.0 and timing.page_load_timeout == 99000
4. `test_underscore_delimiter_does_not_work_for_nested` -- monkeypatch.setenv("TIMING__NAV_DELAY_MIN", "99"), load MINIMAL_YAML, assert timing.nav_delay_min == 2.0 (unchanged, because env_nested_delimiter is None). This documents the known limitation.
5. `test_env_overrides_yaml_value` -- load FULL_YAML which sets search.min_salary=180000 via YAML, then monkeypatch.setenv("SEARCH", json.dumps({"min_salary": 250000, "queries": [{"title": "test"}]})), load settings, assert search.min_salary == 250_000 (env wins over YAML)
6. `test_source_priority_chain` -- Test the full chain: model default (200000) vs YAML value vs env var. Load MINIMAL_YAML (which has no candidate_desired_salary_usd, so default is 200000), assert == 200000. Then monkeypatch.setenv("CANDIDATE_DESIRED_SALARY_USD", "350000"), load again (reset_settings first), assert == 350000. This proves env > yaml > default.
7. `test_env_file_dev_null_isolates_from_real_dotenv` -- explicitly verify that with env_file="/dev/null", no real .env values leak in. Load MINIMAL_YAML, assert dice_password is None (would be set if real .env leaked).
  </action>
  <verify>
Run: `python -m pytest tests/test_config.py -v`
ALL tests pass (both Task 1 and Task 2 classes). Then run full suite:
`python -m pytest tests/ -v --tb=short`
No regressions in existing tests. No config leakage between test files.
  </verify>
  <done>
CFG-03: All optional fields have documented defaults verified -- platforms, timing, schedule, scoring weights, apply config, credentials, candidate profile fields.
CFG-04: Top-level env vars override defaults, credential env vars work, JSON env vars override nested sections, underscore delimiter limitation documented, source priority chain verified (env > yaml > default), .env isolation confirmed.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_config.py -v` -- all tests pass
2. `python -m pytest tests/test_config.py --tb=short -q` -- no failures, no warnings
3. `python -m pytest tests/ -v --tb=short` -- full suite passes, no regressions
4. `python -m pytest tests/test_config.py -v -k "TestConfigLoading"` -- CFG-01 tests pass
5. `python -m pytest tests/test_config.py -v -k "TestConfigValidation"` -- CFG-02 tests pass
6. `python -m pytest tests/test_config.py -v -k "TestConfigDefaults"` -- CFG-03 tests pass
7. `python -m pytest tests/test_config.py -v -k "TestConfigEnvOverrides"` -- CFG-04 tests pass
8. No `job_pipeline/jobs.db` file created during test run (JOBFLOW_TEST_DB=1 working)
</verification>

<success_criteria>
- tests/test_config.py exists with 4 test classes and ~30-40 tests
- All 4 requirements covered: CFG-01 (loading), CFG-02 (validation), CFG-03 (defaults), CFG-04 (env overrides)
- Config isolation fixture prevents .env contamination and model_config leakage
- Full test suite passes with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/13-config-integration-tests/13-01-SUMMARY.md`
</output>
