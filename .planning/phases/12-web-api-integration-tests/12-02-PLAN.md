---
phase: 12-web-api-integration-tests
plan: 02
type: execute
wave: 2
depends_on: ["12-01"]
files_modified:
  - tests/webapp/test_endpoints.py
autonomous: true

must_haves:
  truths:
    - "GET /export/csv returns a valid CSV file parseable by csv.DictReader with 10 header fields"
    - "CSV export contains all expected fields: title, company, location, salary_display, platform, status, score, url, posted_date, created_at"
    - "CSV export row count matches the number of jobs in the database (or filtered subset)"
    - "GET /export/json returns valid JSON parseable by json.loads as a list of dicts"
    - "JSON export contains all expected fields including apply_url and notes (12 fields total)"
    - "JSON export row count matches the number of jobs in the database"
    - "Export endpoints respect filters -- exporting with platform=dice returns only dice jobs"
    - "POST /bulk/status changes status of exactly the specified job_keys and no others"
    - "POST /bulk/status with no job_keys is a no-op (no errors, no changes)"
    - "POST /import reads discovered_jobs.json from pipeline directory and upserts into database"
    - "POST /import returns redirect response (303) to dashboard with imported count"
    - "POST /import with no pipeline files returns redirect with count=0"
  artifacts:
    - path: "tests/webapp/test_endpoints.py"
      provides: "WEB-04, WEB-05, WEB-06, WEB-07: Export, bulk, and import endpoint tests appended to existing file"
      contains: "class TestCsvExport"
  key_links:
    - from: "tests/webapp/test_endpoints.py"
      to: "webapp/app.py"
      via: "TestClient(app) exercising export, bulk, and import routes"
      pattern: "client.get.*export|client.post.*bulk|client.post.*import"
    - from: "tests/webapp/test_endpoints.py"
      to: "webapp/db.py"
      via: "db_module.upsert_job for seeding, db_module.get_job for verification"
      pattern: "db_module.upsert_job|db_module.get_job"
---

<objective>
Write integration tests for export endpoints (WEB-04, WEB-05), bulk status action (WEB-06), and job import (WEB-07).

Purpose: These tests verify data export integrity (CSV parseable, JSON schema-compliant, correct field counts), bulk operations (multi-select status changes), and the pipeline import flow (reading JSON files from disk into the database). Together with Plan 12-01, they complete full coverage of all 8 WEB-* requirements.

Output: TestCsvExport, TestJsonExport, TestBulkStatusEndpoint, and TestImportEndpoint classes appended to tests/webapp/test_endpoints.py.
</objective>

<execution_context>
@/Users/patrykattc/.claude/get-shit-done/workflows/execute-plan.md
@/Users/patrykattc/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-web-api-integration-tests/12-RESEARCH.md
@.planning/phases/12-web-api-integration-tests/12-01-SUMMARY.md
@webapp/app.py
@webapp/db.py
@tests/conftest.py
@tests/webapp/conftest.py
@tests/webapp/test_endpoints.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add CSV and JSON export endpoint tests (WEB-04, WEB-05)</name>
  <files>tests/webapp/test_endpoints.py</files>
  <action>
Append test classes to the existing `tests/webapp/test_endpoints.py` file from Plan 12-01.

**class TestCsvExport (WEB-04):**

- `test_csv_returns_200(self, client, db_with_jobs)`: GET `/export/csv`. Assert 200.
- `test_csv_content_type(self, client, db_with_jobs)`: GET `/export/csv`. Assert `"text/csv"` in `response.headers["content-type"]`.
- `test_csv_has_content_disposition(self, client, db_with_jobs)`: GET `/export/csv`. Assert `"Content-Disposition"` in `response.headers`. Assert `"attachment"` and `".csv"` in the header value.
- `test_csv_parseable_by_csv_module(self, client, db_with_jobs)`: GET `/export/csv`. Parse with `csv.DictReader(io.StringIO(response.text))`. Assert no exception. Read all rows. Assert `len(rows) == 10` (db_with_jobs seeds 10 jobs).
- `test_csv_has_correct_headers(self, client, db_with_jobs)`: Parse CSV. Assert `reader.fieldnames` contains all 10 expected fields: `["title", "company", "location", "salary_display", "platform", "status", "score", "url", "posted_date", "created_at"]`.
- `test_csv_row_data_matches_jobs(self, client)`: Insert a specific job with known title "Staff K8s Engineer" and company "TestCorp". GET `/export/csv`. Parse CSV. Find the row matching "Staff K8s Engineer". Assert company == "TestCorp".
- `test_csv_respects_platform_filter(self, client)`: Insert 2 jobs on different platforms. GET `/export/csv?platform=dice`. Parse CSV. Assert all rows have platform "dice".
- `test_csv_empty_db_returns_headers_only(self, client)`: GET `/export/csv` (no jobs in DB). Parse CSV. Assert 0 rows but headers still present.

**class TestJsonExport (WEB-05):**

- `test_json_returns_200(self, client, db_with_jobs)`: GET `/export/json`. Assert 200.
- `test_json_content_type(self, client, db_with_jobs)`: GET `/export/json`. Assert `"application/json"` in `response.headers["content-type"]`.
- `test_json_has_content_disposition(self, client, db_with_jobs)`: GET `/export/json`. Assert `"Content-Disposition"` in `response.headers`. Assert `"attachment"` and `".json"` in the header value.
- `test_json_parseable(self, client, db_with_jobs)`: GET `/export/json`. Parse with `json.loads(response.text)`. Assert no exception. Assert result is a list. Assert `len(data) == 10`.
- `test_json_has_correct_fields(self, client, db_with_jobs)`: Parse JSON. For each job dict in the list, assert all 12 expected fields present: `["title", "company", "location", "salary_display", "platform", "status", "score", "url", "apply_url", "posted_date", "created_at", "notes"]`.
- `test_json_row_data_matches_jobs(self, client)`: Insert a specific job with known values. GET `/export/json`. Parse JSON. Find matching entry. Assert field values match.
- `test_json_respects_score_filter(self, client)`: Insert 2 jobs with scores 3 and 5. GET `/export/json?score=5`. Parse JSON. Assert all entries have score >= 5.
- `test_json_empty_db_returns_empty_list(self, client)`: GET `/export/json`. Parse JSON. Assert `data == []`.

**Important implementation notes:**
- Import `csv`, `io`, and `json` at the top of the file.
- CSV export uses `StreamingResponse` with `text/csv` media type. The response body is the full CSV string.
- JSON export uses `StreamingResponse` with `application/json` media type. The body is a JSON string (not using `response.json()` -- use `json.loads(response.text)` instead since it is a StreamingResponse, not JSONResponse).
- The `db_with_jobs` fixture seeds 10 jobs across 3 platforms with cycling scores 3, 4, 5.
- Score filter in export: `?score=5` maps to `score_min=5` in `get_jobs()`, returning jobs with score >= 5.
  </action>
  <verify>
Run: `uv run pytest tests/webapp/test_endpoints.py::TestCsvExport -v --tb=short` -- all 8 tests pass.
Run: `uv run pytest tests/webapp/test_endpoints.py::TestJsonExport -v --tb=short` -- all 8 tests pass.
  </verify>
  <done>TestCsvExport has 8 tests covering: 200 response, content-type, content-disposition, csv.DictReader parseability, 10 correct header fields, row data accuracy, platform filter, empty DB. TestJsonExport has 8 tests covering: 200 response, content-type, content-disposition, json.loads parseability, 12 correct fields, row data accuracy, score filter, empty DB. All marked @pytest.mark.integration.</done>
</task>

<task type="auto">
  <name>Task 2: Add bulk status and import endpoint tests (WEB-06, WEB-07)</name>
  <files>tests/webapp/test_endpoints.py</files>
  <action>
Append test classes to the existing `tests/webapp/test_endpoints.py` file.

**class TestBulkStatusEndpoint (WEB-06):**

- `test_bulk_status_returns_200(self, client)`: Insert 2 jobs. POST `/bulk/status` with `data={"job_keys": [key1, key2], "bulk_status": "saved"}`. Assert 200.
- `test_bulk_status_changes_target_jobs(self, client)`: Insert 3 jobs. Select first 2 keys. POST `/bulk/status` with `data={"job_keys": [key1, key2], "bulk_status": "saved"}`. Verify via `db_module.get_job()` that the 2 selected jobs have status "saved". Verify the 3rd job still has status "discovered".
- `test_bulk_status_returns_html(self, client)`: Insert 2 jobs. POST `/bulk/status` with `data={"job_keys": [key1, key2], "bulk_status": "applied"}`. Assert response contains HTML (check for job-related content in `response.text`).
- `test_bulk_status_no_keys_is_noop(self, client)`: Insert 2 jobs. POST `/bulk/status` with `data={"bulk_status": "saved"}` (no job_keys). Assert 200. Verify all jobs still have status "discovered".
- `test_bulk_status_empty_keys_is_noop(self, client)`: Insert 2 jobs. POST `/bulk/status` with `data={"job_keys": [], "bulk_status": "saved"}`. Assert 200. Verify all jobs still have status "discovered".
- `test_bulk_status_logs_activity(self, client)`: Insert 1 job. POST `/bulk/status` with `data={"job_keys": [key], "bulk_status": "applied"}`. Check `db_module.get_activity_log(key)`. Verify a "status_change" entry exists.

**class TestImportEndpoint (WEB-07):**

- `test_import_no_files_redirects(self, client)`: POST `/import` with `follow_redirects=False`. Assert `response.status_code == 303`. Assert `response.headers["location"]` contains `imported=0`.
- `test_import_with_discovered_jobs(self, client, tmp_path, monkeypatch)`: Create a temporary `discovered_jobs.json` file in `tmp_path` containing 2 valid job dicts. Monkeypatch the `pipeline_dir` path in `webapp.app.import_jobs` so it reads from `tmp_path` instead of the real `job_pipeline/` directory. POST `/import` with `follow_redirects=False`. Assert status_code == 303. Assert `imported=2` in redirect location. Verify `db_module.get_job()` returns data for the imported jobs.
- `test_import_with_raw_platform_files(self, client, tmp_path, monkeypatch)`: Create `raw_indeed.json` in `tmp_path` with 1 job dict. Monkeypatch pipeline_dir. POST `/import` with `follow_redirects=False`. Verify imported count includes the raw file.
- `test_import_follows_redirect_to_dashboard(self, client, tmp_path, monkeypatch)`: Create `discovered_jobs.json` with 1 job. Monkeypatch pipeline_dir. POST `/import` (default follow_redirects=True). Assert final response status_code == 200. Assert response is the dashboard page.

**Important implementation notes for the executor:**

**Monkeypatching the import endpoint:**
The `import_jobs` function in `webapp/app.py` computes `pipeline_dir = Path(__file__).parent.parent / "job_pipeline"` as a local variable. To redirect this for testing, monkeypatch the function itself. The cleanest approach:

```python
import webapp.app as app_module

async def _patched_import_jobs(pipeline_path):
    """Create a patched version that reads from tmp_path."""
    # Copy the logic from the real import_jobs but use pipeline_path
    ...

# OR: monkeypatch the Path resolution
# Since pipeline_dir is computed from Path(__file__), one approach is to write
# the test files to the ACTUAL pipeline_dir location and clean up after.
# But the safer approach is to monkeypatch app_module.import_jobs with a
# wrapper that replaces the function entirely.
```

The recommended approach: Rather than patching the whole function, patch `Path.__file__` computation. Actually the simplest is to monkeypatch by replacing the entire `import_jobs` route handler. However, that defeats the purpose of integration testing.

**Best approach:** Write temp files into the real `job_pipeline/` directory for the test and clean up:

```python
def test_import_with_discovered_jobs(self, client, tmp_path):
    pipeline_dir = Path(__file__).resolve().parents[2] / "job_pipeline"
    pipeline_dir.mkdir(exist_ok=True)
    scored_path = pipeline_dir / "discovered_jobs.json"
    backup = scored_path.read_text() if scored_path.exists() else None
    try:
        scored_path.write_text(json.dumps([_make_job_dict("ImportCo", "Import Engineer")]))
        response = client.post("/import", follow_redirects=False)
        assert response.status_code == 303
        assert "imported=" in response.headers["location"]
    finally:
        if backup:
            scored_path.write_text(backup)
        elif scored_path.exists():
            scored_path.unlink()
```

**Even better approach:** Monkeypatch the `Path` object used in the function. The function computes `pipeline_dir = Path(__file__).parent.parent / "job_pipeline"`. Monkeypatch by overriding the entire coroutine:

```python
import json
from pathlib import Path

async def _mock_import(original_fn, tmp_path, job_dicts):
    """Write job_dicts to tmp_path and patch the route."""
    # Write discovered_jobs.json to tmp_path
    (tmp_path / "discovered_jobs.json").write_text(json.dumps(job_dicts))
    # Monkeypatch the route handler to use tmp_path
    ...
```

**Simplest correct approach:** Use `monkeypatch.setattr` on `webapp.app` to replace a module-level constant or use `monkeypatch.chdir(tmp_path)` combined with writing to the relative path. But `Path(__file__)` is absolute, so chdir doesn't help.

**Final recommendation:** Create a helper that monkeypatches the `import_jobs` async function in `webapp.app` module to use a custom pipeline_dir:

```python
def _patch_import(monkeypatch, tmp_path):
    """Replace import_jobs route handler to read from tmp_path."""
    original_import = app_module.import_jobs

    async def patched_import():
        pipeline_dir = tmp_path
        count = 0
        scored_path = pipeline_dir / "discovered_jobs.json"
        if scored_path.exists():
            data = json.loads(scored_path.read_text())
            count += db_module.upsert_jobs(data)
        for name in ("raw_indeed.json", "raw_dice.json", "raw_remoteok.json"):
            raw_path = pipeline_dir / name
            if raw_path.exists():
                data = json.loads(raw_path.read_text())
                count += db_module.upsert_jobs(data)
        from fastapi.responses import RedirectResponse
        return RedirectResponse(url="/?imported=" + str(count), status_code=303)

    monkeypatch.setattr(app_module, "import_jobs", patched_import)
```

This is the cleanest approach -- it tests the real route behavior (reads JSON, upserts, redirects) but redirects disk I/O to `tmp_path`.

**Bulk status form data:** TestClient correctly encodes `data={"job_keys": [key1, key2], "bulk_status": "saved"}` as multi-value form fields. No special encoding needed.
  </action>
  <verify>
Run: `uv run pytest tests/webapp/test_endpoints.py::TestBulkStatusEndpoint -v --tb=short` -- all 6 tests pass.
Run: `uv run pytest tests/webapp/test_endpoints.py::TestImportEndpoint -v --tb=short` -- all 4 tests pass.
Run: `uv run pytest tests/webapp/test_endpoints.py -v --tb=short` -- all tests pass (30 from Plan 12-01 + 16 from this plan = 46 total).
  </verify>
  <done>TestBulkStatusEndpoint has 6 tests covering: 200 response, selective status changes, HTML response body, no-keys no-op, empty-keys no-op, activity logging. TestImportEndpoint has 4 tests covering: no-files redirect with count=0, discovered_jobs.json import with count verification, raw platform file import, redirect following to dashboard. All marked @pytest.mark.integration.</done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/webapp/test_endpoints.py -v --tb=short` -- all 46 tests pass
2. `uv run pytest tests/webapp/test_endpoints.py -m integration -v` -- all tests correctly marked as integration
3. `uv run pytest tests/ -v --tb=short -q` -- all existing tests still pass (no regressions)
4. Verify CSV is parseable: `python -c "import csv, io; csv.DictReader(io.StringIO(open('/dev/null').read()))"` -- no import errors
</verification>

<success_criteria>
- TestCsvExport has 8 tests verifying CSV structure, parseability, correct 10-field headers, data accuracy, filtering, and empty DB
- TestJsonExport has 8 tests verifying JSON structure, parseability, correct 12-field schema, data accuracy, filtering, and empty DB
- TestBulkStatusEndpoint has 6 tests verifying selective status changes and no-op edge cases
- TestImportEndpoint has 4 tests verifying pipeline JSON import, redirect behavior, and empty pipeline handling
- All tests pass with `uv run pytest tests/webapp/test_endpoints.py -v`
- All tests marked with `@pytest.mark.integration`
- Total endpoint tests: 46 (30 from Plan 12-01 + 16 from this plan)
</success_criteria>

<output>
After completion, create `.planning/phases/12-web-api-integration-tests/12-02-SUMMARY.md`
</output>
