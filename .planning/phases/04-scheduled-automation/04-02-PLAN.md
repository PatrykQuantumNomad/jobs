---
phase: 04-scheduled-automation
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - webapp/db.py
  - webapp/app.py
  - webapp/templates/run_history.html
  - orchestrator.py
autonomous: true

must_haves:
  truths:
    - "Every pipeline run (both manual and scheduled) records a row in run_history with started_at, finished_at, mode, platforms searched, job counts, errors, status, and duration"
    - "The run_history table is created by the existing migration system (SCHEMA_VERSION bump) and survives DB restarts"
    - "GET /runs in the web dashboard displays a table of recent pipeline runs with timestamp, mode, platforms, jobs found, new jobs, errors, status, and duration"
    - "Partial failures (some platforms error, others succeed) are recorded as status='partial' with error details in the errors JSON array"
    - "busy_timeout pragma is set on all SQLite connections to handle concurrent access between dashboard and scheduled pipeline"
  artifacts:
    - path: "webapp/db.py"
      provides: "run_history table schema, migration, record_run(), get_run_history() functions"
      contains: "run_history"
    - path: "webapp/app.py"
      provides: "/runs dashboard endpoint"
      contains: "/runs"
    - path: "webapp/templates/run_history.html"
      provides: "Run history table view"
    - path: "orchestrator.py"
      provides: "Run history recording at pipeline completion"
      contains: "record_run"
  key_links:
    - from: "orchestrator.py"
      to: "webapp/db.py"
      via: "Calls webdb.record_run() at end of run() with timing and job counts"
      pattern: "record_run"
    - from: "webapp/app.py"
      to: "webapp/db.py"
      via: "Calls db.get_run_history() to populate /runs template"
      pattern: "get_run_history"
    - from: "webapp/app.py"
      to: "webapp/templates/run_history.html"
      via: "Renders run history template with list of runs"
      pattern: "run_history.html"
---

<objective>
Add run history recording to the pipeline and expose it on the web dashboard.

Purpose: Without run history, scheduled runs are invisible -- the user has no way to know when the last run happened, whether it succeeded, or how many new jobs it found. This plan closes the observability gap so the user can trust the scheduler is working correctly.
Output: run_history table in SQLite, recording at end of every pipeline run, /runs dashboard page showing all past runs.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-scheduled-automation/04-RESEARCH.md
@.planning/phases/04-scheduled-automation/04-01-SUMMARY.md

@webapp/db.py
@webapp/app.py
@webapp/templates/base.html
@orchestrator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add run_history table, busy_timeout, and query functions to webapp/db.py</name>
  <files>webapp/db.py</files>
  <action>
**Schema migration** -- Bump `SCHEMA_VERSION` from 2 to 3. Add migration 3 to `MIGRATIONS` dict:

```python
3: [
    """CREATE TABLE IF NOT EXISTS run_history (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        started_at TEXT NOT NULL,
        finished_at TEXT NOT NULL,
        mode TEXT NOT NULL DEFAULT 'manual',
        platforms_searched TEXT NOT NULL DEFAULT '[]',
        total_raw INTEGER DEFAULT 0,
        total_scored INTEGER DEFAULT 0,
        new_jobs INTEGER DEFAULT 0,
        errors TEXT DEFAULT '[]',
        status TEXT NOT NULL DEFAULT 'success',
        duration_seconds REAL DEFAULT 0.0
    )""",
],
```

**busy_timeout** -- Add `conn.execute("PRAGMA busy_timeout = 5000")` in `get_conn()` right after the WAL pragma, for BOTH the memory and file paths. This prevents "database is locked" errors when the dashboard and scheduled pipeline access the DB simultaneously.

**record_run function:**

```python
def record_run(
    started_at: str,
    finished_at: str,
    mode: str,
    platforms_searched: list[str],
    total_raw: int,
    total_scored: int,
    new_jobs: int,
    errors: list[str],
    status: str,
    duration_seconds: float,
) -> None:
    """Record a pipeline run in the run_history table."""
    with get_conn() as conn:
        conn.execute(
            """INSERT INTO run_history
               (started_at, finished_at, mode, platforms_searched,
                total_raw, total_scored, new_jobs, errors, status, duration_seconds)
               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
            (
                started_at, finished_at, mode,
                json.dumps(platforms_searched),
                total_raw, total_scored, new_jobs,
                json.dumps(errors), status, duration_seconds,
            ),
        )
```

**get_run_history function:**

```python
def get_run_history(limit: int = 50) -> list[dict]:
    """Return recent pipeline runs, newest first."""
    with get_conn() as conn:
        rows = conn.execute(
            "SELECT * FROM run_history ORDER BY id DESC LIMIT ?",
            (limit,),
        ).fetchall()
    return [dict(row) for row in rows]
```
  </action>
  <verify>
Run: `python -c "
import os
os.environ['JOBFLOW_TEST_DB'] = '1'
from webapp import db
db._memory_conn = None  # Reset
db.init_db()
db.record_run(
    started_at='2026-02-07T08:00:00',
    finished_at='2026-02-07T08:05:30',
    mode='scheduled',
    platforms_searched=['indeed', 'remoteok'],
    total_raw=150,
    total_scored=20,
    new_jobs=5,
    errors=[],
    status='success',
    duration_seconds=330.0,
)
runs = db.get_run_history()
assert len(runs) == 1
r = runs[0]
assert r['mode'] == 'scheduled'
assert r['total_raw'] == 150
assert r['new_jobs'] == 5
assert r['status'] == 'success'
print(f'Run history OK: {r[\"started_at\"]} -> {r[\"status\"]}, {r[\"new_jobs\"]} new jobs')
"`
  </verify>
  <done>run_history table created via migration 3 (SCHEMA_VERSION=3). busy_timeout=5000 on all connections. record_run() persists run metadata. get_run_history() returns runs newest-first.</done>
</task>

<task type="auto">
  <name>Task 2: Record run history in orchestrator and add /runs dashboard endpoint</name>
  <files>orchestrator.py, webapp/app.py, webapp/templates/run_history.html</files>
  <action>
**orchestrator.py** -- Wrap the `run()` method to record timing and outcome:

1. At the top of `run()`, capture start time:
```python
import time as _time
run_start = _time.monotonic()
run_started_at = datetime.now().isoformat()
run_errors: list[str] = []
```

2. Wrap the main pipeline body in try/except to capture errors. Each platform search error should append to `run_errors` (the existing `except` in `_search_platform` prints but doesn't record -- add `run_errors` as an instance attribute `self._run_errors`).

Actually, cleaner approach: Add `self._run_errors: list[str] = []` in `__init__`. In `_search_platform`, when catching exceptions, also append to `self._run_errors`. In `_login_platform`, when catching exceptions, also append to `self._run_errors`.

3. At the end of `run()`, BEFORE `_print_summary()`, record the run:
```python
run_finished_at = datetime.now().isoformat()
run_duration = _time.monotonic() - run_start

# Count raw jobs from files
total_raw = 0
for name in get_all_platforms():
    raw_path = JOB_PIPELINE_DIR / f"raw_{name}.json"
    if raw_path.exists():
        total_raw += len(json.loads(raw_path.read_text()))

run_status = "success"
if self._run_errors:
    if self.discovered_jobs:
        run_status = "partial"
    else:
        run_status = "failed"

webdb.record_run(
    started_at=run_started_at,
    finished_at=run_finished_at,
    mode="scheduled" if self.scheduled else "manual",
    platforms_searched=self.searched_platforms,
    total_raw=total_raw,
    total_scored=len(self.discovered_jobs),
    new_jobs=sum(1 for j in self.discovered_jobs if j.score and j.score >= 3),
    errors=self._run_errors,
    status=run_status,
    duration_seconds=round(run_duration, 1),
)
```

4. Wrap the entire pipeline body (phases 0-4) in a try/except so even crashes get recorded:
```python
def run(self, platforms: list[str] | None = None) -> None:
    ...
    run_start = _time.monotonic()
    run_started_at = datetime.now().isoformat()

    try:
        self.phase_0_setup()
        self.phase_1_login(platforms)
        # ... existing pipeline code ...
        self._print_summary()
    except Exception as exc:
        self._run_errors.append(f"Pipeline crash: {exc}")
        raise
    finally:
        # Always record the run, even on crash
        run_finished_at = datetime.now().isoformat()
        run_duration = _time.monotonic() - run_start
        # ... record_run call ...
```

**webapp/app.py** -- Add a `/runs` endpoint:

```python
@app.get("/runs", response_class=HTMLResponse)
async def run_history(request: Request):
    runs = db.get_run_history(limit=50)
    return templates.TemplateResponse(
        "run_history.html",
        {"request": request, "runs": runs},
    )
```

Add `parse_json` filter usage note: the `platforms_searched` and `errors` fields are JSON strings in the DB rows. The existing `parse_json` Jinja2 filter (added in 03-03) handles this.

**webapp/templates/run_history.html** -- Create a new template that extends `base.html`:

- Page title: "Run History"
- Navigation link back to dashboard
- Table with columns: Time, Mode, Platforms, Raw Jobs, Scored (3+), New Jobs, Errors, Status, Duration
- `started_at` displayed as readable datetime (use Jinja2 slicing: `{{ run.started_at[:19] }}`)
- `mode` displayed with a badge: "manual" (blue) or "scheduled" (green)
- `platforms_searched` parsed from JSON string to display as comma-separated list
- `errors` parsed from JSON -- if non-empty, show count with expandable details
- `status` displayed with color badge: success (green), partial (yellow), failed (red)
- `duration_seconds` displayed as "Xm Ys" format (e.g., "5m 30s")
- Style consistent with existing dashboard (same Tailwind classes, same base template)
- If no runs exist, show "No pipeline runs recorded yet" message

Also add a "Run History" link in the base template or dashboard navigation. Check `base.html` for nav structure and add a link to `/runs`.
  </action>
  <verify>
Run: `python -c "
import os
os.environ['JOBFLOW_TEST_DB'] = '1'
from webapp import db
db._memory_conn = None
db.init_db()
# Record two runs
db.record_run('2026-02-07T08:00:00', '2026-02-07T08:05:00', 'scheduled', ['indeed', 'remoteok'], 150, 20, 5, [], 'success', 300.0)
db.record_run('2026-02-07T09:00:00', '2026-02-07T09:02:00', 'manual', ['dice'], 50, 10, 3, ['Dice: login timeout'], 'partial', 120.0)
runs = db.get_run_history()
assert len(runs) == 2
assert runs[0]['mode'] == 'manual'  # Newest first
assert runs[1]['mode'] == 'scheduled'
print(f'Run history query OK: {len(runs)} runs, newest={runs[0][\"started_at\"]}')
"`

Run: `python -c "from webapp.app import app; routes = [r.path for r in app.routes]; assert '/runs' in routes; print('Route /runs exists')"` -- confirms endpoint registered

Run: `test -f webapp/templates/run_history.html && echo 'Template exists' || echo 'MISSING'`
  </verify>
  <done>Every pipeline run (manual and scheduled) records to run_history with timing, job counts, errors, and status. /runs dashboard page shows all past runs with color-coded status badges. Partial failures recorded with error details. busy_timeout prevents concurrent access issues.</done>
</task>

</tasks>

<verification>
1. `python -c "import os; os.environ['JOBFLOW_TEST_DB']='1'; from webapp import db; db._memory_conn=None; db.init_db(); db.record_run('2026-02-07T08:00:00','2026-02-07T08:05:00','scheduled',['indeed'],100,15,5,[],'success',300.0); r=db.get_run_history(); assert len(r)==1; print('DB OK')"` -- run history round-trips through SQLite
2. `python -c "from webapp.app import app; routes=[r.path for r in app.routes]; assert '/runs' in routes; print('/runs endpoint OK')"` -- endpoint registered
3. `test -f webapp/templates/run_history.html && echo 'Template OK'` -- template file exists
4. `grep -c 'record_run' orchestrator.py` -- should be >= 1 (recording at end of run)
5. `grep -c 'busy_timeout' webapp/db.py` -- should be >= 1 (concurrent access protection)
6. Run history records both "manual" and "scheduled" modes based on --scheduled flag
7. Pipeline crashes still record a run_history entry (via finally block)
</verification>

<success_criteria>
- run_history table exists after DB migration (SCHEMA_VERSION=3)
- record_run() persists all 10 fields correctly
- get_run_history() returns runs newest-first with configurable limit
- Orchestrator records every run (manual and scheduled) with accurate timing and counts
- Pipeline crashes still produce a run_history entry
- /runs dashboard page renders a readable table of past runs
- busy_timeout=5000 on all SQLite connections
- Partial failures (some platforms error) recorded as status='partial'
</success_criteria>

<output>
After completion, create `.planning/phases/04-scheduled-automation/04-02-SUMMARY.md`
</output>
